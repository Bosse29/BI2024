---
title: '2'
author: "GhazalArzanian"
date: "2024-11-12"
output: html_document
---

### Part 2

First we look at the head of the data to see how does the data look like.And also to check the variables types. As we can see all the variables are numbbers num or int.

```{r}
df <- read.csv("miami-housing.csv")
data<-df
str(data)
summary(data)

```
#### Corellation
In this step we want to look that variables that have more than 0.5 absolute correlation with each other.
```{r}

correlations <- cor(data, use = "complete.obs")

high_corr <- which(abs(correlations) > 0.5 & abs(correlations) < 1, arr.ind = TRUE)

high_corr_pairs <- data.frame(
  Column1 = rownames(correlations)[high_corr[, 1]],
  Column2 = colnames(correlations)[high_corr[, 2]],
  Correlation = correlations[high_corr]
)

high_corr_pairs <- high_corr_pairs[!duplicated(t(apply(high_corr_pairs[, 1:2], 1, sort))), ]

print(high_corr_pairs)

```
#### Removing duplicated rows

Check if the Parcelno is the a unique identifier ?
As we see there are some rows that have the same parcelno numbers.It means they are different records for the same property. So since the data is for one yearwe will consider the later month and delete the earlier months.
```{r}
duplicate_rows <- data[duplicated(data$PARCELNO) | duplicated(data$PARCELNO, fromLast = TRUE), ]
duplicate_rows

```
CHECK IF ALWAYS THE LAST MONTHES HAS THE HIGHER PRICES? 
AS we see the higher price is not always for the last month.
```{r}
library(dplyr)
result <- data %>%
  filter(duplicated(PARCELNO) | duplicated(PARCELNO, fromLast = TRUE)) %>%
  group_by(PARCELNO) %>%
  arrange(PARCELNO, month_sold) %>%
  mutate(
    max_month = max(month_sold),                    
    is_latest_month = month_sold == max_month,         
    is_price_higher_for_latest_month = SALE_PRC == max(SALE_PRC[is_latest_month]) 
  ) %>%
  ungroup() %>%
  filter(is_latest_month != is_price_higher_for_latest_month) 

print(result)
```

FILTER THE ROW THAT HAVE SAME PARVELNO AND DIFFERENT MONTHES WITH THE LAST MONTH.
We keep the record with the last month for the rows that have equal parcelno.
```{r}

library(dplyr)

  group_by(PARCELNO) %>%
  filter(month_sold == max(month_sold)) %>%
  ungroup()

```
THE DUPLICATED ONE THAT ARE LEFT ARE THE ONE WITH THE SAME MONTH.
```{r}
duplicate_rows <- data[duplicated(data$PARCELNO) | duplicated(data$PARCELNO, fromLast = TRUE), ]
duplicate_rows
```
FOR THE RECORDS WITH THE SAME MONTH AND THE SAME PARCELNO WE CACULATE THE AVERAGAE SALE_PRC.

```{r}

library(dplyr)

aggregated_data <- data %>%
  group_by(PARCELNO) %>%
  summarise(
    SALE_PRC = mean(SALE_PRC, na.rm = TRUE),
    across(-SALE_PRC, ~ first(.))
  ) %>%
  ungroup()

```

```{r}
duplicate_rows <- aggregated_data[duplicated(aggregated_data$PARCELNO) | duplicated(aggregated_data$PARCELNO, fromLast = TRUE), ]
duplicate_rows
```
Now we have a clean data that dosent have duplicated PARCELNO.
```{r}
data<-aggregated_data
```
### 2.b. Statistical properties
```{r}
summary(data)
```
We check if there is any correlation between numeric values (all the vriables in this data) or not.
```{r}
correlations <- cor(data[sapply(data, is.numeric)], use = "complete.obs")
print(correlations)

```
#### Missing values
The data is clean and we dont have any missing data.

```{r}
colSums(is.na(data))
```

#### Distribution of the numeric values and plots
We use boxplot and histogram to look that the distribution of the varibles.

```{r}

numeric_cols <- data[sapply(data, is.numeric)]
numeric_cols$PARCELNO <- NULL
barplot_columns <- c("structure_quality", "month_sold", "avno60plus", "age")

for (col in names(numeric_cols)) {
  if (col %in% barplot_columns) {
  
    freq_table <- table(numeric_cols[[col]])
    barplot(freq_table, main = paste("Frequency of values in", col), xlab = col, ylab = "Frequency", 
            col = "lightblue", border = "black")
  } else {
    hist(numeric_cols[[col]], main = paste("Histogram of", col), xlab = col, col = "lightblue", border = "black")
  }
}


boxplot(numeric_cols, main = "Boxplot of Numerical Attributes", las = 2)
```




As we see in the boxplot the average sale price has a high range and we want to look throught this column to find the outliers.

```{r}
boxplot(data$SALE_PRC, main = "Boxplot of SALE_PRC", ylab = "Sale Price")

```




```{r}
Q1 <- quantile(data$SPEC_FEAT_VAL, 0.25)
Q3 <- quantile(data$SPEC_FEAT_VAL, 0.75)
IQR <- Q3 - Q1
outliers <- data[data$SPEC_FEAT_VAL < (Q1 - 1.5 * IQR) | data$SPEC_FEAT_VAL> (Q3 + 1.5 * IQR), ]
print(outliers)


```
We Wanted to see if there is any outlier in the data or not. We considered "avg_sale_prc", "age", "LND_SQFOOT", "structure_quality", "CNTR_DIST" and made the scatterplot for them as we can see there is not any specific outlier with the combined variables.

```{r}
library(GGally)
selected_data <- data[, c("SALE_PRC", "age", "LND_SQFOOT", "structure_quality", "CNTR_DIST")]
ggpairs(selected_data, 
        title = "Scatterplot Matrix for Selected Variables")



```
```{r}
library(ggplot2)

ggplot(data, aes(x = age, y = CNTR_DIST)) +
  geom_point(color = "blue", size = 2, alpha = 0.5) +
  geom_smooth(method = "lm", color = "red", se = FALSE) + # Add regression line
  labs(title = "Age vs Distance to Center with Trend Line",
       x = "Age",
       y = "Distance to City Center") +
  theme_minimal()


```
```{r}
library(ggplot2)
ggplot(data, aes(x = TOT_LVG_AREA, y = SPEC_FEAT_VAL)) +
  geom_point(color = "blue", size = 2, alpha = 0.5) +
  geom_smooth(method = "lm", color = "red", se = FALSE) +
  labs(title = "Total Living Area vs Special Feature Value with Trend Line",
       x = "Total Living Area",
       y = "Special Feature Value") +
  theme_minimal()


```
```{r}
library(ggplot2)

ggplot(data, aes(x = TOT_LVG_AREA, y = SALE_PRC)) +
  geom_point(color = "blue", size = 2, alpha = 0.5) +
  geom_smooth(method = "lm", color = "red", se = FALSE) +
  labs(title = "Scatterplot of Total Living Area vs Sale Price",
       x = "Total Living Area",
       y = "Sale Price") +
  theme_minimal()

```
```{r}
data$structure_quality <- as.factor(data$structure_quality)

plot(data$structure_quality, data$SALE_PRC,
     xlab = "Structure Quality Grades",
     ylab = "Sale Price",
     main = "Scatterplot of Structure Quality vs Sale Price",
     pch = 19, col = rgb(0, 0, 1, alpha = 0.5))

```





#### Turning LATITUDE & LONGTITUDE columns to zipcodes
```{r}

library(sf)
library(tigris)
library(dplyr)

options(tigris_use_cache = TRUE)

zctas <- zctas(cb = TRUE, year = 2016)  # Adjust the year as needed

```

```{r}
df<-data 
df$LATITUDE <- as.numeric(df$LATITUDE)
df$LONGITUDE <- as.numeric(df$LONGITUDE)

df <- df %>% filter(!is.na(LATITUDE) & !is.na(LONGITUDE))

df_sf <- st_as_sf(df, coords = c("LONGITUDE", "LATITUDE"), crs = 4326)

zctas <- st_transform(zctas, st_crs(df_sf))
names(zctas)
```
```{r}

zip_code_column <- "ZCTA5CE10" 

df_with_zip <- st_join(df_sf, zctas[zip_code_column], left = TRUE)

df_with_zip <- df_with_zip %>% rename(ZIP_CODE = all_of(zip_code_column))


```
```{r}
df_with_zip$geometry <- NULL
unique(df_with_zip$ZIP_CODE) 



```
### Part 3

####Preprocessing:
First we remove the identifier from the data . It is not nessecary when we want to give the data to the model.
Then as we saw on the plot the sale_prc has a right skewed distribution so we just get the log out of it to have a better distributin of it.

```{r}
df_with_zip <- df_with_zip %>% select(-PARCELNO)
```
```{r}
df_with_zip$SALE_PRC <- log(df_with_zip$SALE_PRC)
```

```{r}
# Plot histogram of the log-transformed SALE_PRC
hist(df_with_zip$SALE_PRC, 
     breaks = 30, 
     main = "Histogram of Log-Transformed SALE_PRC", 
     xlab = "Log(SALE_PRC)", 
     col = "skyblue")


```
Now we want to scale the numerical columns . Many machin learning models work better when features are on a similar scale .
```{r}
numerical_cols <- c("LND_SQFOOT", "TOT_LVG_AREA", "SPEC_FEAT_VAL", "RAIL_DIST",
                    "OCEAN_DIST", "WATER_DIST", "CNTR_DIST", "SUBCNTR_DI",
                    "HWY_DIST", "age", "avno60plus")
df_with_zip[numerical_cols] <- scale(df_with_zip[numerical_cols])

```


```{r,echo=FALSE}
install.packages("fastDummies")
```
For preprocessing the zipcode column we decided to make another coulmn call region which is the district of the zipcode.With that we will have 13 distingushed district which is easier to use one-hot encoding on it.

```{r}
library(dplyr)

# Define regions and ZIP codes
regions_list <- list(
  "Miami Beach" = c("33139", "33140", "33141", "33154", "33160", "33180"),
  "Hialeah Gardens" = c("33018"),
  "Hialeah" = c("33010", "33012", "33013", "33014", "33015", "33016"),
  "Opa-locka" = c("33054", "33055", "33056"),
  "Northeast" = c("33161", "33162", "33179", "33181", "33138", "33137", "33132"),
  "Coral Gables" = c("33146"),
  "Coconut Grove" = c("33133"),
  "Southwest Miami" = c("33155", "33156", "33157", "33158", "33165", "33173",
                        "33175", "33176", "33177", "33183", "33186", "33187",
                        "33189", "33193", "33196", "33194", "33184", "33144",
                        "33174", "33134", "33135", "33145", "33185", "33143",
                        "33170", "33190"),
  "Homestead" = c("33030", "33031", "33032", "33033", "33034", "33035", "33039"),
  "Downtown Miami" = c("33128", "33129", "33130", "33131"),
  "Key Biscayne" = c("33149"),
  "NW Miami" = c("33192", "33182", "33172", "33178", "33166", "33122", "33126",
                 "33169", "33167", "33168", "33147", "33150", "33142", "33127",
                 "33136", "33125")
)

# Create mapping dataframe
zip_region_df <- data.frame(ZIP_CODE = character(), Region = character(), stringsAsFactors = FALSE)
for (region in names(regions_list)) {
  zips <- regions_list[[region]]
  temp_df <- data.frame(ZIP_CODE = zips, Region = region, stringsAsFactors = FALSE)
  zip_region_df <- rbind(zip_region_df, temp_df)
}

# Ensure 'ZIP_CODE' is character
df_with_zip$ZIP_CODE <- as.character(df_with_zip$ZIP_CODE)
zip_region_df$ZIP_CODE <- as.character(zip_region_df$ZIP_CODE)

# Merge to assign regions
df_with_zip <- merge(df_with_zip, zip_region_df, by = "ZIP_CODE", all.x = TRUE)

# Assign 'Other' to missing regions
df_with_zip$Region[is.na(df_with_zip$Region)] <- "Other"
```
```{r}
unique(df_with_zip$Region) 


```

```{r}
# Encode 'Region' (choose one encoding method)
df_with_zip <- dummy_cols(df_with_zip, select_columns = "Region", remove_first_dummy = TRUE, remove_selected_columns = TRUE)


```


```{r}
data<-df_with_zip
```





